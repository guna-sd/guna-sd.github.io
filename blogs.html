<!DOCTYPE html>
<html lang="en">

<head>
    <title>Guna-sd | Blogs</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="gunasekar, Guna-sd, sd.gunaseker, s.d.gunaseker, guna, gunaseker" />
    <meta name="description" content="Explore Guna-sd's blogs.">
    <link rel="stylesheet" href="style.css">
    <script src="script.js"></script>
</head>

<body class="image0">
    <div class="page">
        <nav class="navbar">
            <ul class="nav-links">
                <li><a href="index.html" class="nav-link">Home</a></li>
                <li><a href="blogs.html" class="nav-link active">Blogs</a></li>
                <li><a href="projects.html" class="nav-link">Projects</a></li>
                <li><a href="about.html" class="nav-link">About</a></li>
                <li class="dropdown">
                    <a href="#" class="dropbutton nav-link">More &#9660;</a>
                    <div class="dropdown-menu">
                        <a href="learn.html" class="nav-link">temp</a>
                        <a href="cv.html" class="nav-link">Resume(cv)</a>
                        <a href="contact.html" class="nav-link">Contact</a>
                    </div>
                </li>
            </ul>
        </nav>
    </div>
    <div class="blogs">
        <div class="blog-overview">
            <div class="blog-post" onclick="showPostDetail('post1')">
                <h2 class="blog-title">what is llm???</h2>
                <p class="blog-content">A large language model (LLM) is a language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process. LLMs are artificial neural networks following a transformer architecture...</p>
                <p class="blog-meta">Published on Jan 3,2024</p>
            </div>
            <div class="blog-post" onclick="showPostDetail('post2')">
                <h2 class="blog-title">sparse attention???</h2>
                <p class="blog-content">A Sparse Transformer is a Transformer based architecture which utilises sparse factorizations of the attention matrix to reduce time/memory to . Other changes to the Transformer architecture include: (a) a restructured residual block and weight initialization, (b) A set of sparse attention kernels which efficiently compute subsets of the attention matrix, (c) recomputation of attention weights during the backwards pass to reduce memory usage...</p>
                <p class="blog-meta">Published on Jan 4,2024</p>
            </div>
            <!-- Add more blog posts here -->
        </div>

        <!-- Blog Post Details Container (Initially Hidden) -->
        <div class="blog-details" id="postDetails">
            <!-- Blog Post Details will be dynamically loaded here -->
        </div>
    </div>
</body>

</html>
